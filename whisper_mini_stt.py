"""
ìœˆë„ìš° ìŠ¤í”¼ì»¤ ì¶œë ¥ ì‹¤ì‹œê°„ í•œêµ­ì–´ STT ì‹œìŠ¤í…œ
Whisper ê¸°ë°˜ - ìŠ¤í”¼ì»¤ì—ì„œ ë‚˜ì˜¤ëŠ” ì†Œë¦¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
webrtcvad ì—†ì´ ì‘ë™ (numpyë§Œ ì‚¬ìš©)
"""

import whisper
import numpy as np
import soundcard as sc
import threading
import queue
import time
from datetime import datetime
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')


class RealtimeSpeakerSTT:
    """ì‹¤ì‹œê°„ ìŠ¤í”¼ì»¤ ì¶œë ¥ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ"""

    def __init__(self, model_size="base", language="ko"):
        """
        Args:
            model_size: "tiny", "base", "small", "medium", "large-v3"
                       ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•´ "base" ë˜ëŠ” "small" ì¶”ì²œ
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: "ko" - í•œêµ­ì–´)
        """
        print("=" * 80)
        print("ğŸ™ï¸ ì‹¤ì‹œê°„ ìŠ¤í”¼ì»¤ ì¶œë ¥ STT ì‹œìŠ¤í…œ")
        print("=" * 80)
        print()

        self.model_size = model_size
        self.language = language
        self.sample_rate = 32000
        self.chunk_duration = 5.0  # 3ì´ˆë§ˆë‹¤ ë³€í™˜
        self.is_running = False

        # ì˜¤ë””ì˜¤ ë²„í¼
        self.audio_queue = queue.Queue()
        self.text_results = []

        # ìŒì„± ê°ì§€ ì„¤ì •
        self.silence_threshold = 0.005  # ìŒëŸ‰ ì„ê³„ê°’ (ì¡°ì ˆ ê°€ëŠ¥)
        self.min_speech_duration = 0.5  # ìµœì†Œ ìŒì„± ê¸¸ì´ (ì´ˆ)

        # ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ”„ Whisper {model_size} ëª¨ë¸ ë¡œë”© ì¤‘...")
        print("   (ì²˜ìŒ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        self.model = whisper.load_model(model_size)
        print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        print()

    def list_speakers(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í”¼ì»¤(ì¶œë ¥ ì¥ì¹˜) ëª©ë¡ í‘œì‹œ"""
        print("=" * 80)
        print("ğŸ”Š ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í”¼ì»¤ (ì¶œë ¥ ì¥ì¹˜)")
        print("=" * 80)
        print()

        try:
            # ëª¨ë“  ìŠ¤í”¼ì»¤ ê°€ì ¸ì˜¤ê¸°
            speakers = sc.all_speakers()

            if not speakers:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í”¼ì»¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print()
                print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                print("   1. ìœˆë„ìš° ì„¤ì • â†’ ì‹œìŠ¤í…œ â†’ ì†Œë¦¬ â†’ ì¶œë ¥ ì¥ì¹˜ í™•ì¸")
                print("   2. ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ í™œì„±í™”:")
                print("      ì œì–´íŒ â†’ ì†Œë¦¬ â†’ ë…¹ìŒ íƒ­ â†’ ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ ìš°í´ë¦­ â†’ í™œì„±í™”")
                return None

            for i, speaker in enumerate(speakers):
                is_default = "(ê¸°ë³¸ê°’)" if i == 0 else ""
                print(f"{i+1}. {speaker.name} {is_default}")

            print()
            return speakers

        except Exception as e:
            print(f"âŒ ìŠ¤í”¼ì»¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            print()
            print("ğŸ’¡ ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰í•´ë³´ì„¸ìš”.")
            return None

    def select_speaker(self):
        """ìŠ¤í”¼ì»¤ ì„ íƒ"""
        speakers = self.list_speakers()

        if not speakers:
            return None

        while True:
            try:
                choice = input(f"ìŠ¤í”¼ì»¤ ì„ íƒ (1-{len(speakers)}, ê¸°ë³¸ê°’=1): ").strip()

                if not choice:
                    choice = "1"

                idx = int(choice) - 1

                if 0 <= idx < len(speakers):
                    selected = speakers[idx]
                    print(f"âœ… ì„ íƒë¨: {selected.name}")
                    print()
                    return selected
                else:
                    print(f"âŒ 1-{len(speakers)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            except KeyboardInterrupt:
                print("\nâŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return None

    def is_speech(self, audio_chunk):
        """
        ì˜¤ë””ì˜¤ ì²­í¬ì— ìŒì„±ì´ ìˆëŠ”ì§€ ê°„ë‹¨íˆ íŒë‹¨
        (webrtcvad ëŒ€ì‹  ìŒëŸ‰ ê¸°ë°˜ ê°ì§€)
        """
        # RMS (Root Mean Square) ê³„ì‚°
        rms = np.sqrt(np.mean(audio_chunk**2))

        # ì„ê³„ê°’ ì´ìƒì´ë©´ ìŒì„±ìœ¼ë¡œ íŒë‹¨
        return rms > self.silence_threshold

    def audio_capture_thread(self, speaker):
        """ì˜¤ë””ì˜¤ ìº¡ì²˜ ìŠ¤ë ˆë“œ"""
        print("ğŸ§ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘...")

        chunk_samples = int(self.chunk_duration * self.sample_rate)

        try:
            # ìŠ¤í”¼ì»¤ ì¶œë ¥ì„ ë£¨í”„ë°±ìœ¼ë¡œ ë…¹ìŒ
            with sc.get_microphone(
                id=str(speaker.name),
                include_loopback=True
            ).recorder(samplerate=self.sample_rate, channels=1) as mic:

                print("âœ… ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ")
                print()

                while self.is_running:
                    # ì˜¤ë””ì˜¤ ì²­í¬ ë…¹ìŒ
                    audio_chunk = mic.record(numframes=chunk_samples)

                    # ëª¨ë…¸ë¡œ ë³€í™˜
                    if len(audio_chunk.shape) > 1:
                        audio_chunk = audio_chunk.mean(axis=1)

                    audio_flat = audio_chunk.flatten()

                    # ìŒì„±ì´ ìˆëŠ”ì§€ ì²´í¬
                    if self.is_speech(audio_flat):
                        # íì— ì¶”ê°€
                        self.audio_queue.put(audio_flat)

        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì˜¤ë¥˜: {e}")
            print()
            print("ğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   1. ë‹¤ë¥¸ ìŠ¤í”¼ì»¤ë¥¼ ì„ íƒí•´ë³´ì„¸ìš”")
            print("   2. ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ë¥¼ í™œì„±í™”í•˜ì„¸ìš”")
            print("   3. í”„ë¡œê·¸ë¨ì„ ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš”")
            self.is_running = False

    def transcribe_thread(self):
        """ìŒì„± ì¸ì‹ ìŠ¤ë ˆë“œ"""
        print("ğŸ“ ìŒì„± ì¸ì‹ ì¤€ë¹„ ì™„ë£Œ")
        print()
        print("=" * 80)
        print("ğŸ¬ ë³€í™˜ ì‹œì‘! ìŠ¤í”¼ì»¤ì—ì„œ ì†Œë¦¬ë¥¼ ë‚´ë³´ì„¸ìš”")
        print("=" * 80)
        print()

        segment_count = 0

        while self.is_running:
            try:
                # íì—ì„œ ì˜¤ë””ì˜¤ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 1ì´ˆ)
                audio_chunk = self.audio_queue.get(timeout=1.0)

                # Whisperë¡œ ë³€í™˜
                result = self.model.transcribe(
                    audio_chunk,
                    language=self.language,
                    task="transcribe",
                    fp16=True,
                    verbose=False,
                    temperature=0.0,
                    compression_ratio_threshold=2.4,
                    logprob_threshold=-1.0,
                    no_speech_threshold=0.6
                )

                text = result['text'].strip()

                # í…ìŠ¤íŠ¸ê°€ ìˆê³  ì˜ë¯¸ìˆëŠ” ê¸¸ì´ë©´ ì¶œë ¥
                if text and len(text) > 1:
                    segment_count += 1
                    timestamp = datetime.now().strftime("%H:%M:%S")

                    # ì»¬ëŸ¬ ì¶œë ¥ (ìœˆë„ìš° í„°ë¯¸ë„ ì§€ì›)
                    print(f"[{timestamp}] #{segment_count:03d}: {text}")

                    # ê²°ê³¼ ì €ì¥
                    self.text_results.append({
                        'timestamp': timestamp,
                        'segment': segment_count,
                        'text': text
                    })

            except queue.Empty:
                continue
            except Exception as e:
                if self.is_running:
                    print(f"âš ï¸ ë³€í™˜ ì˜¤ë¥˜: {e}")

    def start(self, speaker):
        """ì‹¤ì‹œê°„ STT ì‹œì‘"""
        print("=" * 80)
        print("ğŸš€ ì‹¤ì‹œê°„ ë³€í™˜ ì‹œì‘")
        print("=" * 80)
        print()
        print("ğŸ’¡ ì‚¬ìš© ë°©ë²•:")
        print("   1. ë…¸íŠ¸ë¶ì—ì„œ ìœ íŠœë¸Œ, ì˜ìƒ, ìŒì•… ë“±ì„ ì¬ìƒí•˜ì„¸ìš”")
        print("   2. ìŠ¤í”¼ì»¤ë¡œ ë‚˜ì˜¤ëŠ” ì†Œë¦¬ê°€ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤")
        print("   3. ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
        print()
        print(f"âš™ï¸  ì„¤ì •:")
        print(f"   - ëª¨ë¸: Whisper {self.model_size}")
        print(f"   - ì²­í¬ ê¸¸ì´: {self.chunk_duration}ì´ˆ")
        print(f"   - ìŒëŸ‰ ì„ê³„ê°’: {self.silence_threshold}")
        print()
        print("=" * 80)
        print()

        self.is_running = True

        # ì˜¤ë””ì˜¤ ìº¡ì²˜ ìŠ¤ë ˆë“œ ì‹œì‘
        capture_thread = threading.Thread(
            target=self.audio_capture_thread,
            args=(speaker,),
            daemon=True
        )
        capture_thread.start()

        # ìŒì„± ì¸ì‹ ìŠ¤ë ˆë“œ ì‹œì‘
        transcribe_thread = threading.Thread(
            target=self.transcribe_thread,
            daemon=True
        )
        transcribe_thread.start()

        try:
            # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” ëŒ€ê¸°
            while self.is_running:
                time.sleep(0.1)
        except KeyboardInterrupt:
            print("\n\nâš ï¸ ì¢…ë£Œ ì¤‘...")
            self.stop()

    def stop(self):
        """ì‹¤ì‹œê°„ STT ì¤‘ì§€"""
        self.is_running = False
        time.sleep(1)  # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°

        print()
        print("=" * 80)
        print("âœ… ë³€í™˜ ì¢…ë£Œ")
        print("=" * 80)
        print()
        print(f"ğŸ“Š ì´ {len(self.text_results)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ë³€í™˜ë¨")
        print()

    def save_results(self, output_dir="output"):
        """ê²°ê³¼ ì €ì¥"""
        if not self.text_results:
            print("ğŸ’¾ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        Path(output_dir).mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        print("=" * 80)
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        print("=" * 80)
        print()

        # 1. íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸ íŒŒì¼
        txt_path = f"{output_dir}/realtime_transcript_{timestamp}.txt"
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ì‹¤ì‹œê°„ ìŠ¤í”¼ì»¤ ì¶œë ¥ ë³€í™˜ ê²°ê³¼\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ëª¨ë¸: Whisper {self.model_size}\n")
            f.write(f"ì´ ì„¸ê·¸ë¨¼íŠ¸: {len(self.text_results)}ê°œ\n")
            f.write("=" * 80 + "\n\n")

            for item in self.text_results:
                f.write(f"[{item['timestamp']}] #{item['segment']:03d}\n")
                f.write(f"{item['text']}\n\n")

        print(f"âœ… íƒ€ì„ìŠ¤íƒ¬í”„ í…ìŠ¤íŠ¸: {txt_path}")

        # 2. ì „ì²´ í…ìŠ¤íŠ¸ë§Œ (êµ¬ë‘ì  í¬í•¨)
        full_text_path = f"{output_dir}/realtime_transcript_{timestamp}_full.txt"
        with open(full_text_path, 'w', encoding='utf-8') as f:
            full_text = " ".join([item['text'] for item in self.text_results])
            f.write(full_text)

        print(f"âœ… ì „ì²´ í…ìŠ¤íŠ¸: {full_text_path}")

        # 3. ë§ˆí¬ë‹¤ìš´ í˜•ì‹
        md_path = f"{output_dir}/realtime_transcript_{timestamp}.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(f"# ì‹¤ì‹œê°„ ë³€í™˜ ê²°ê³¼\n\n")
            f.write(f"**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**ëª¨ë¸**: Whisper {self.model_size}\n\n")
            f.write(f"**ì´ ì„¸ê·¸ë¨¼íŠ¸**: {len(self.text_results)}ê°œ\n\n")
            f.write("---\n\n")

            f.write("## ì „ì²´ ë‚´ìš©\n\n")
            full_text = " ".join([item['text'] for item in self.text_results])
            f.write(full_text + "\n\n")

            f.write("---\n\n")
            f.write("## íƒ€ì„ìŠ¤íƒ¬í”„ë³„ ë‚´ìš©\n\n")

            for item in self.text_results:
                f.write(f"### [{item['timestamp']}] #{item['segment']:03d}\n\n")
                f.write(f"{item['text']}\n\n")

        print(f"âœ… ë§ˆí¬ë‹¤ìš´: {md_path}")

        print()
        print("=" * 80)
        print("âœ… ëª¨ë“  íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
        print("=" * 80)
        print()
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
        print()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print()
    print("=" * 80)
    print("ğŸ™ï¸ ì‹¤ì‹œê°„ ìŠ¤í”¼ì»¤ ì¶œë ¥ â†’ í•œêµ­ì–´ STT ì‹œìŠ¤í…œ")
    print("=" * 80)
    print()
    print("âœ¨ íŠ¹ì§•:")
    print("   - ìœˆë„ìš° ìŠ¤í”¼ì»¤ ì¶œë ¥ ì‹¤ì‹œê°„ ìº¡ì²˜")
    print("   - ìœ íŠœë¸Œ, ì˜ìƒ, ìŒì•… ë“± ëª¨ë“  ì†Œë¦¬ ë³€í™˜")
    print("   - í•œêµ­ì–´ ìë™ ì¸ì‹")
    print("   - ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì¶œë ¥")
    print("   - ìë™ êµ¬ë‘ì  ì²˜ë¦¬")
    print()
    print("=" * 80)
    print()

    # ëª¨ë¸ í¬ê¸° ì„ íƒ
    print("ğŸ“Š ëª¨ë¸ í¬ê¸° ì„ íƒ (ì‹¤ì‹œê°„ ì²˜ë¦¬ìš©):")
    print("  1. tiny    - ë§¤ìš° ë¹ ë¦„ (ì •í™•ë„ ë‚®ìŒ) âš¡")
    print("  2. base    - ë¹ ë¦„ (ì •í™•ë„ ë³´í†µ) â­ ì¶”ì²œ!")
    print("  3. small   - ì¤‘ê°„ (ì •í™•ë„ ì¢‹ìŒ)")
    print("  4. medium  - ëŠë¦¼ (ì •í™•ë„ ë†’ìŒ)")
    print()

    choice = input("ì„ íƒ (1-4, ê¸°ë³¸ê°’=2): ").strip() or "2"

    model_sizes = {
        "1": "tiny",
        "2": "base",
        "3": "small",
        "4": "medium"
    }

    model_size = model_sizes.get(choice, "base")

    print()
    print(f"âœ… {model_size} ëª¨ë¸ ì„ íƒë¨")
    print()

    # STT ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    try:
        stt_system = RealtimeSpeakerSTT(
            model_size=model_size,
            language="ko"
        )
    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print()
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   pip install --upgrade openai-whisper torch")
        return

    # ìŠ¤í”¼ì»¤ ì„ íƒ
    speaker = stt_system.select_speaker()

    if speaker is None:
        print("âŒ ìŠ¤í”¼ì»¤ë¥¼ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print()
        print("ğŸ’¡ ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ í™œì„±í™” ë°©ë²•:")
        print("   1. ìœˆë„ìš° ê²€ìƒ‰ â†’ 'ì†Œë¦¬ ì„¤ì •'")
        print("   2. ê³ ê¸‰ â†’ ë…¹ìŒ íƒ­")
        print("   3. ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ ìš°í´ë¦­ â†’ í™œì„±í™”")
        print("   4. í”„ë¡œê·¸ë¨ ì¬ì‹¤í–‰")
        return

    # ì‹¤ì‹œê°„ STT ì‹œì‘
    try:
        stt_system.start(speaker)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ê²°ê³¼ ì €ì¥
        if stt_system.text_results:
            print()
            save_choice = input("ğŸ’¾ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’=y): ").strip().lower()
            if save_choice != 'n':
                stt_system.save_results()

        print()
        print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        print()


if __name__ == "__main__":
    main()