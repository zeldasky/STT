"""
Whisper Large-v3 ê¸°ë°˜ í•œêµ­ì–´ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œìŠ¤í…œ
ìµœê³  ì •í™•ë„, êµ¬ë‘ì  ìë™ ì²˜ë¦¬, ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°
"""

import whisper
import warnings
import os
from pathlib import Path
from datetime import datetime
import json
from tqdm import tqdm
import torch

warnings.filterwarnings('ignore')


class WhisperLargeV3STT:
    """Whisper Large-v3 ê¸°ë°˜ í•œêµ­ì–´ STT ì‹œìŠ¤í…œ"""

    def __init__(self, use_gpu=False):
        """
        Args:
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€ (False=CPU, True=CUDA)
        """
        print("=" * 80)
        print("ğŸ™ï¸ Whisper Large-v3 í•œêµ­ì–´ STT ì‹œìŠ¤í…œ")
        print("=" * 80)
        print()

        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if use_gpu and torch.cuda.is_available():
            self.device = "cuda"
            print("ğŸš€ NVIDIA GPU ì‚¬ìš©")
        else:
            self.device = "cpu"
            print("ğŸ’» CPU ì‚¬ìš© (ì•ˆì •ì„± ìš°ì„ )")

        print()
        print("ğŸ”„ Whisper Large-v3 ëª¨ë¸ ë¡œë”© ì¤‘...")
        print("   (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì•½ 3GB ë‹¤ìš´ë¡œë“œ - ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        print()

        try:
            # Whisper large-v3 ëª¨ë¸ ë¡œë“œ
            self.model = whisper.load_model("large-v3", device=self.device)
            print("âœ… Whisper Large-v3 ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            print()
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            print()
            print("ğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   pip install --upgrade openai-whisper")
            raise

    def transcribe_file(self, audio_path, language="ko", verbose=True):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: "ko" - í•œêµ­ì–´)
            verbose: ì§„í–‰ ìƒí™© í‘œì‹œ ì—¬ë¶€

        Returns:
            dict: ë³€í™˜ ê²°ê³¼ (segments, text í¬í•¨)
        """
        print("=" * 80)
        print(f"ğŸ“‚ ì˜¤ë””ì˜¤ íŒŒì¼: {audio_path}")
        print("=" * 80)
        print()

        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")

        # íŒŒì¼ ì •ë³´
        file_size = os.path.getsize(audio_path) / (1024 * 1024)  # MB
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
        print()

        print("ğŸš€ ìŒì„± ì¸ì‹ ì‹œì‘...")
        print("   (ê¸´ ì˜¤ë””ì˜¤ëŠ” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        print()

        try:
            # Whisper ë³€í™˜ ìˆ˜í–‰
            result = self.model.transcribe(
                audio_path,
                language=language,
                task="transcribe",
                verbose=verbose,
                fp16=False,  # CPU í˜¸í™˜ì„±
                temperature=0.0,  # ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼
                beam_size=5,  # ì •í™•ë„ í–¥ìƒ
                best_of=5,  # ìµœê³  í’ˆì§ˆ
                patience=1.0  # ì•ˆì •ì„±
            )

            print()
            print("âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ!")
            print()

            return result

        except Exception as e:
            print(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def format_results(self, result):
        """
        Whisper ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            result: Whisper ë³€í™˜ ê²°ê³¼

        Returns:
            list: í‘œì¤€í™”ëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        formatted_results = []

        for segment in result['segments']:
            formatted_results.append({
                'id': segment['id'],
                'start': segment['start'],
                'end': segment['end'],
                'text': segment['text'].strip(),
                'speaker': 'Speaker_0'  # ê¸°ë³¸ í™”ì
            })

        return formatted_results

    def save_results(self, result, formatted_results, output_dir="output", audio_filename="audio"):
        """
        ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥

        Args:
            result: ì›ë³¸ Whisper ê²°ê³¼
            formatted_results: í‘œì¤€í™”ëœ ê²°ê³¼
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            audio_filename: ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ëª…
        """
        Path(output_dir).mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = f"{audio_filename}_{timestamp}"

        print("=" * 80)
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        print("=" * 80)
        print()

        # 1. ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥ (êµ¬ë‘ì  í¬í•¨)
        full_text_path = f"{output_dir}/{base_name}_full.txt"
        with open(full_text_path, 'w', encoding='utf-8') as f:
            f.write(result['text'])
        print(f"âœ… ì „ì²´ í…ìŠ¤íŠ¸: {full_text_path}")

        # 2. íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸
        timestamped_path = f"{output_dir}/{base_name}_timestamped.txt"
        with open(timestamped_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("íšŒì˜ë¡ ìë™ ë³€í™˜ ê²°ê³¼ (Whisper Large-v3)\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 80 + "\n\n")

            for item in formatted_results:
                start_min = int(item['start'] // 60)
                start_sec = int(item['start'] % 60)
                end_min = int(item['end'] // 60)
                end_sec = int(item['end'] % 60)

                f.write(f"[{start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}]\n")
                f.write(f"{item['text']}\n\n")
        print(f"âœ… íƒ€ì„ìŠ¤íƒ¬í”„ í…ìŠ¤íŠ¸: {timestamped_path}")

        # 3. JSON ì €ì¥ (í”„ë¡œê·¸ë˜ë° ìš©ë„)
        json_path = f"{output_dir}/{base_name}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'model': 'whisper-large-v3',
                    'language': result.get('language', 'ko'),
                    'duration': formatted_results[-1]['end'] if formatted_results else 0,
                    'timestamp': datetime.now().isoformat()
                },
                'full_text': result['text'],
                'segments': formatted_results
            }, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSON íŒŒì¼: {json_path}")

        # 4. ë§ˆí¬ë‹¤ìš´ ì €ì¥ (ì½ê¸° ì¢‹ì€ í˜•ì‹)
        md_path = f"{output_dir}/{base_name}.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(f"# íšŒì˜ë¡\n\n")
            f.write(f"**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**ëª¨ë¸**: Whisper Large-v3\n\n")
            f.write(f"**ì´ ê¸¸ì´**: {formatted_results[-1]['end'] / 60:.1f}ë¶„\n\n" if formatted_results else "")
            f.write("---\n\n")

            f.write("## ì „ì²´ ë‚´ìš©\n\n")
            f.write(result['text'] + "\n\n")

            f.write("---\n\n")
            f.write("## íƒ€ì„ìŠ¤íƒ¬í”„ë³„ ë‚´ìš©\n\n")

            for item in formatted_results:
                start_min = int(item['start'] // 60)
                start_sec = int(item['start'] % 60)
                end_min = int(item['end'] // 60)
                end_sec = int(item['end'] % 60)

                f.write(f"### [{start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}]\n\n")
                f.write(f"{item['text']}\n\n")
        print(f"âœ… ë§ˆí¬ë‹¤ìš´ íŒŒì¼: {md_path}")

        # 5. SRT ìë§‰ íŒŒì¼ (ì˜ìƒ ìë§‰ìš©)
        srt_path = f"{output_dir}/{base_name}.srt"
        with open(srt_path, 'w', encoding='utf-8') as f:
            for i, item in enumerate(formatted_results, 1):
                start_time = self._format_srt_time(item['start'])
                end_time = self._format_srt_time(item['end'])

                f.write(f"{i}\n")
                f.write(f"{start_time} --> {end_time}\n")
                f.write(f"{item['text']}\n\n")
        print(f"âœ… SRT ìë§‰ íŒŒì¼: {srt_path}")

        print()
        print("=" * 80)
        print("âœ… ëª¨ë“  íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
        print("=" * 80)

    def _format_srt_time(self, seconds):
        """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (00:00:00,000)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    def print_summary(self, result, formatted_results):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print()
        print("=" * 80)
        print("ğŸ“Š ë³€í™˜ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)
        print()
        print(f"ğŸ¯ ì´ ì„¸ê·¸ë¨¼íŠ¸: {len(formatted_results)}ê°œ")
        print(f"â±ï¸  ì´ ê¸¸ì´: {formatted_results[-1]['end'] / 60:.1f}ë¶„" if formatted_results else "")
        print(f"ğŸ“ ì´ ê¸€ì ìˆ˜: {len(result['text'])}ì")
        print(f"ğŸ—£ï¸  ì–¸ì–´: {result.get('language', 'ko').upper()}")
        print()

        # ì²˜ìŒ 3ê°œ ì„¸ê·¸ë¨¼íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        print("=" * 80)
        print("ğŸ“„ ë³€í™˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 3ê°œ)")
        print("=" * 80)
        print()

        for item in formatted_results[:3]:
            start_min = int(item['start'] // 60)
            start_sec = int(item['start'] % 60)
            end_min = int(item['end'] // 60)
            end_sec = int(item['end'] % 60)

            print(f"[{start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}]")
            print(f"{item['text']}")
            print()

        if len(formatted_results) > 3:
            print(f"... ì™¸ {len(formatted_results) - 3}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
            print()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print()
    print("=" * 80)
    print("ğŸ™ï¸ Whisper Large-v3 í•œêµ­ì–´ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œìŠ¤í…œ")
    print("=" * 80)
    print()
    print("âœ¨ íŠ¹ì§•:")
    print("   - ìµœê³  ìˆ˜ì¤€ì˜ í•œêµ­ì–´ ì¸ì‹ ì •í™•ë„")
    print("   - ìë™ êµ¬ë‘ì  ì²˜ë¦¬")
    print("   - ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°")
    print("   - íƒ€ì„ìŠ¤íƒ¬í”„ ìë™ ìƒì„±")
    print()
    print("=" * 80)
    print()

    # GPU ì‚¬ìš© ì—¬ë¶€ ì„ íƒ
    use_gpu_input = input("ğŸš€ GPUë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’=n): ").strip().lower()
    use_gpu = use_gpu_input == 'y'

    print()

    # STT ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    try:
        stt_system = WhisperLargeV3STT(use_gpu=use_gpu)
    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return

    # ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì…ë ¥
    print("=" * 80)
    audio_path = input("ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ë“œë˜ê·¸ ì•¤ ë“œë¡­ ê°€ëŠ¥): ").strip()
    audio_path = audio_path.replace('\\ ', ' ').strip("'\"")

    if not os.path.exists(audio_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        return

    print()

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    output_dir = input("ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’=output): ").strip() or "output"

    print()
    print("=" * 80)
    print("âš™ï¸ ì„¤ì • í™•ì¸")
    print("=" * 80)
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {audio_path}")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {'GPU (CUDA)' if use_gpu else 'CPU'}")
    print(f"ğŸ¤– ëª¨ë¸: Whisper Large-v3")
    print("=" * 80)
    print()

    confirm = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    if confirm != 'y':
        print("âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    print()

    try:
        # STT ìˆ˜í–‰
        result = stt_system.transcribe_file(audio_path, language="ko", verbose=True)

        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = stt_system.format_results(result)

        # ê²°ê³¼ ì €ì¥
        audio_filename = Path(audio_path).stem
        stt_system.save_results(result, formatted_results, output_dir, audio_filename)

        # ìš”ì•½ ì¶œë ¥
        stt_system.print_summary(result, formatted_results)

        print()
        print("=" * 80)
        print("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("=" * 80)
        print()
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: {output_dir}/")
        print()

    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()